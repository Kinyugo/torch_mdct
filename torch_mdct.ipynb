{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch MDCT\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "from torchaudio import functional as F\n",
    "\n",
    "from torch_mdct import MDCT, InverseMDCT\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate, title):\n",
    "    channels, n_frames = waveform.shape\n",
    "\n",
    "    skip = int(n_frames / (0.01 * n_frames))\n",
    "    waveform = waveform[..., 0:-1:skip]\n",
    "\n",
    "    n_frames = waveform.shape[-1]\n",
    "    time_axis = torch.linspace(0,\n",
    "                               n_frames / (sample_rate / skip),\n",
    "                               steps=n_frames)\n",
    "\n",
    "    fig, axes = plt.subplots(2, max(channels // 2, 1), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for c in range(channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "\n",
    "        if channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c}\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_spectrogram(spectrogram, title):\n",
    "    channels = spectrogram.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(2, max(channels // 2, 1), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for c in range(channels):\n",
    "        im = axes[c].imshow(torch.log(spectrogram[c].abs() + 1e-5),\n",
    "                            origin=\"lower\",\n",
    "                            aspect=\"auto\")\n",
    "        fig.colorbar(im, ax=axes[c])\n",
    "\n",
    "        if channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channels {c}\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def stats(x):\n",
    "    print(\n",
    "        f\"Shape: {x.shape} Min: {x.min():.4f} Max: {x.max():.4f} Mean: {x.mean():.4f} Std: {x.std():.4f}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(\"sample_audio.ogg\")\n",
    "stats(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdct = MDCT(win_length=2048)\n",
    "imdct = InverseMDCT(win_length=2048)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform audio into mdct specgram\n",
    "specgram = mdct(waveform)\n",
    "stats(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mdct specgram\n",
    "plot_spectrogram(specgram, \"Log Absolute MDCT Spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mdct spectrogram back to audio\n",
    "waveform_reconst = imdct(specgram, length=waveform.shape[-1])\n",
    "stats(waveform_reconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original audio\n",
    "plot_waveform(waveform, sample_rate, \"Original Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to the original audio\n",
    "Audio(waveform, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reconstructed audio\n",
    "plot_waveform(waveform_reconst, sample_rate, \"Reconstructed Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to the reconstructed audio\n",
    "Audio(waveform_reconst, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 distance between the two audio samples\n",
    "print(f\"L1 Loss: {(waveform - waveform_reconst).abs().mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c339664639c3e5019e3803d0baff2aab4fdaac0204aae143f6ed0f1a6cb76161"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
